{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7921917a",
   "metadata": {},
   "source": [
    "# 疲劳数据整理\n",
    "  所有疲劳数据整理，每一个目标值建立一个全部特征值的csv文件，舍弃目标值为空的行。\n",
    "  热处理因为数据过于紊乱，所以采用字符串的全连接方式，如需要特定的目标值可以split得到。\n",
    "## 库引入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acee5427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from typing import Tuple, List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2992b2",
   "metadata": {},
   "source": [
    "## 查询字典加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908e5b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "for feature_name in ['化学成分', '金相组织', '热处理工艺']:\n",
    "    with open(f\"./{feature_name}.json\", \"r\") as f:\n",
    "        features.append(json.load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a991355e",
   "metadata": {},
   "source": [
    "## 整理函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91834ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_features(row: pd.Series) -> pd.Series:\n",
    "    features_rows = [row]\n",
    "    if all(name if name in row.keys() else False for name in {'钢号', '热处理号', '炉号'}):\n",
    "        chemical_composition = features[0].get(f\"{row['钢号']}-{row['炉号']}\", None)\n",
    "        microstructure = features[1].get(f\"{row['钢号']}-{row['炉号']}-{row['热处理号']}\", None)\n",
    "        hot_process = features[2].get(f\"{row['钢号']}-{row['热处理号']}\", None)\n",
    "        if chemical_composition:\n",
    "            features_rows.append(pd.Series(data=chemical_composition, index=features[0][\"column_names\"]))\n",
    "        if microstructure:\n",
    "            features_rows.append(pd.Series(data=microstructure, index=features[1][\"column_names\"]))\n",
    "        if hot_process:\n",
    "            features_rows.append(pd.Series(data=hot_process, index=features[2][\"column_names\"]))\n",
    "    elif all(key if name in row.keys() else False for name in {'钢号', '炉号'}):\n",
    "        chemical_composition = features[0].get(f\"{row['钢号']}-{row['炉号']}\", None)\n",
    "        if chemical_composition:\n",
    "            features_rows.append(pd.Series(data=chemical_composition, index=features[0][\"column_names\"]))\n",
    "    elif all(key if name in row.keys() else False for name in {'钢号', '热处理号'}):\n",
    "        hot_process = features[2].get(f\"{row['钢号']}-{row['热处理号']}\", None)\n",
    "        if hot_process:\n",
    "            features_rows.append(pd.Series(data=hot_process, index=features[2][\"column_names\"]))\n",
    "    return pd.concat(features_rows, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e089ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv(save_root_path: str, file_name: str, results: List[pd.DataFrame],\n",
    "              target_names: Tuple[str]) -> None:\n",
    "    save_father_path = os.path.join(save_root_path, file_name)\n",
    "    if not os.path.exists(save_father_path):\n",
    "        os.mkdir(save_father_path)\n",
    "    if not target_names:\n",
    "        save_path = os.path.join(save_father_path, f\"{file_name}.csv\")\n",
    "        results[0].to_csv(save_path, encoding=\"gbk\")\n",
    "    else:\n",
    "        for target_name, result in zip(target_names, results):\n",
    "            save_path = os.path.join(save_father_path, f\"{target_name}.csv\")\n",
    "            result.to_csv(save_path, encoding=\"gbk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db906537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tidy_data(data__root_path: str, file_name: str, target_names: List[str]) -> List[pd.DataFrame]:    \n",
    "    data_path = os.path.join(data_root_path, f'{process_file_name}.csv')\n",
    "    original_data = pd.read_csv(data_path, encoding='gbk')\n",
    "    results = [pd.DataFrame() for target_name in target_names] if target_name else [pd.DataFrame()]       \n",
    "    for index, row in original_data.iterrows():\n",
    "        if not target_names:\n",
    "            result_row = connect_features(row)\n",
    "            results[0] = results[result_index].append(result_row, ignore_index=True)\n",
    "        else:\n",
    "            for result_index, target_name in enumerate(target_names):\n",
    "                if not row[target_name]:\n",
    "                    continue\n",
    "                # connect all features\n",
    "                result_row = connect_features(row)\n",
    "                # drop other targets\n",
    "                drop_target = target_names[:]\n",
    "                drop_target.remove(target_name)\n",
    "                result_row.drop(drop_target, inplace=True)\n",
    "                results[result_index] = results[result_index].append(result_row, ignore_index=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb491ee3",
   "metadata": {},
   "source": [
    "## 主函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b2495e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root_path = '/home/yuyouyu/WorkSpace/106Lab_Data/fatigue_original'\n",
    "process_file_name = '抗拉强度'\n",
    "data_path = os.path.join(data_root_path, f'{process_file_name}.csv')\n",
    "target_names = ['断面收缩率', '伸长率10', '伸长率5', '抗拉强度', '屈服点']\n",
    "original_data = pd.read_csv(data_path, encoding='gbk')\n",
    "results = [pd.DataFrame() for target_name in target_names]\n",
    "for index, row in original_data.iterrows():\n",
    "    for result_index, target_name in enumerate(target_names):\n",
    "        if not row[target_name]:\n",
    "            continue\n",
    "        result_row = connect_features(row)\n",
    "        drop_target = target_names[:]\n",
    "        drop_target.remove(target_name)\n",
    "        result_row.drop(drop_target, inplace=True)\n",
    "        results[result_index] = results[result_index].append(result_row, ignore_index=True)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
