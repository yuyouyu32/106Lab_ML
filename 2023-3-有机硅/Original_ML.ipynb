{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from edRVFL import EnsembleDeepRVFL\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = True\n",
    "SCALER = StandardScaler\n",
    "folds = 10\n",
    "\n",
    "num_nodes = 10  # Number of enhancement nodes.\n",
    "regular_para = 1  # Regularization parameter.\n",
    "weight_random_range = [-1, 1]  # Range of random weights.\n",
    "bias_random_range = [0, 1]  # Range of random weights.\n",
    "num_layer = 10  # Number of hidden layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict2csv(ave_score, ave_mse, ave_mape, save_path):\n",
    "    df_score = pd.DataFrame.from_dict(ave_score, orient='index')\n",
    "    df_score.to_excel(f'./{save_path}_score.xlsx', index=False)\n",
    "    df_mse = pd.DataFrame.from_dict(ave_mse, orient='index')\n",
    "    df_mse.to_excel(f'./{save_path}_mse.xlsx', index=False)\n",
    "    df_mape = pd.DataFrame.from_dict(ave_mape, orient='index')\n",
    "    df_mape.to_excel(f'./{save_path}_mape.xlsx', index=False)\n",
    "\n",
    "def read_data(file, target_name, all_targets, normal=False):\n",
    "    data = pd.read_excel(file).fillna(0).astype('float64')\n",
    "    targets = data.loc[:, target_name].values\n",
    "    features = data.drop(columns=all_targets).values\n",
    "    if normal:\n",
    "        scaler_1 = SCALER()\n",
    "        features = scaler_1.fit_transform(features)\n",
    "        # scaler_2 = SCALER()\n",
    "        # targets = scaler_2.fit_transform(targets.reshape(-1, 1)).reshape(-1)\n",
    "    return features, targets\n",
    "\n",
    "\n",
    "def modelHelper(model, x_train, x_test, y_train, y_test):\n",
    "    if isinstance(model, EnsembleDeepRVFL):\n",
    "        model = EnsembleDeepRVFL(n_nodes=num_nodes, lam=regular_para, w_random_vec_range=weight_random_range,b_random_vec_range=bias_random_range, activation='relu', n_layer=num_layer, same_feature=False,task_type='regression')\n",
    "        model.train(x_train, y_train, 0)\n",
    "        y_pred = model.predict(x_test)\n",
    "        # result[model_name][target_name]['y'] = y_pred\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    else:\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        # result[model_name][target_name]['y'] = y_pred\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    return r2, mse, mape\n",
    "    # print(f'[{model_name}] [{target_name}] r2 = {r2}')\n",
    "    # print(f'[{model_name}] [{target_name}] MSE = {mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = './Data/data.xlsx'\n",
    "data = pd.read_excel(file).fillna(0).astype('float64')\n",
    "all_targets = data.columns.to_list()[-9:]\n",
    "# data.describe().to_csv('./results/describe.csv')\n",
    "result = {}\n",
    "ave_score = {}\n",
    "ave_mse = {}\n",
    "ave_mape = {}\n",
    "\n",
    "kf = KFold(n_splits=folds, shuffle=True, random_state=17)\n",
    "# from sklearn.model_selection import LeaveOneOut\n",
    "# kf = LeaveOneOut()\n",
    "# folds = 'leaveone'\n",
    "\n",
    "for target_name in all_targets:\n",
    "    print(f'#########################{target_name}#################################')\n",
    "    result[target_name] = {}\n",
    "    ave_score[target_name] = {}\n",
    "    ave_mse[target_name] = {}\n",
    "    ave_mape[target_name] = {}\n",
    "\n",
    "    features, targets = read_data(file=file, target_name=target_name, all_targets=all_targets, normal= normal)\n",
    "    for model_name in ['SVR', 'Ridge', 'Lasso', 'SGD', 'DT', 'RF', 'XGboost', 'edRVFL']:\n",
    "        result[target_name][model_name] = {}\n",
    "        result[target_name][model_name]['scores'] = []\n",
    "        result[target_name][model_name]['MSEs'] = []\n",
    "        result[target_name][model_name]['MAPEs'] = []\n",
    "\n",
    "        # Reset the models\n",
    "        for fold , (train_index, test_index) in enumerate(kf.split(features)):\n",
    "            models = {'SVR': SVR(gamma='auto'), 'RF': RandomForestRegressor(n_estimators=100), 'Ridge': Ridge(alpha=1),\n",
    "            'Lasso': Lasso(max_iter=5000, alpha=1), 'SGD': SGDRegressor(max_iter=5000, alpha=1), 'DT': DecisionTreeRegressor(), \n",
    "            'XGboost': XGBRegressor(max_depth=50, learning_rate=0.1, n_estimators=100), 'edRVFL': EnsembleDeepRVFL(n_nodes=num_nodes, lam=regular_para,w_random_vec_range=weight_random_range,b_random_vec_range=bias_random_range, activation='relu', n_layer=num_layer, same_feature=False,task_type='regression')}\n",
    "            model = models[model_name]\n",
    "            x_train, y_train = features[train_index], targets[train_index]\n",
    "            x_test, y_test = features[test_index], targets[test_index]\n",
    "            r2, mse, mape = modelHelper(model, x_train, x_test, y_train, y_test)\n",
    "            result[target_name][model_name]['scores'].append(r2)\n",
    "            result[target_name][model_name]['MSEs'].append(mse)\n",
    "            result[target_name][model_name]['MAPEs'].append(mape)\n",
    "        ave_score[target_name][model_name] = np.mean(result[target_name][model_name]['scores'])\n",
    "        ave_mse[target_name][model_name] = np.mean(result[target_name][model_name]['MSEs'])\n",
    "        ave_mape[target_name][model_name] = np.mean(result[target_name][model_name]['MAPEs'])\n",
    "        print(f'{model_name}: ', ave_mape[target_name][model_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not normal:\n",
    "    dict2csv(ave_score=ave_score, ave_mse=ave_mse, ave_mape=ave_mape, save_path=f'./results/nonor_{folds}fold')\n",
    "elif normal and SCALER is MinMaxScaler:\n",
    "    dict2csv(ave_score=ave_score, ave_mse=ave_mse, ave_mape=ave_mape, save_path=f'./results/maxmin_{folds}fold')\n",
    "elif normal and SCALER is StandardScaler:\n",
    "    dict2csv(ave_score=ave_score, ave_mse=ave_mse, ave_mape=ave_mape, save_path=f'./results/stand_{folds}fold_T')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yyy_multimodal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ae4bac3e47f8e3b90b58bb90b13b6b01bf9f3b4d39b843b45c66ea43b26ed5e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
